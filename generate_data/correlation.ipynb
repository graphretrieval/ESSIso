{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random \n",
    "import numpy as np \n",
    "from tqdm import tqdm \n",
    "from scipy.spatial.distance import cdist, cosine\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from utils.corrupt_graph import remove_edge, remove_node, add_edge, add_node\n",
    "from utils.query_machine import get_candidates\n",
    "from python_emb import *\n",
    "import torch.nn.functional as F\n",
    "from scipy.spatial.distance import cosine\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_label_class(future):\n",
    "    labels = list(future.keys())\n",
    "    values = [max(len(future[i][0]), len(future[i][1])) for i in labels]\n",
    "    selected_label = labels[np.argmin(np.array(values))]\n",
    "    return selected_label, future[selected_label]\n",
    "\n",
    "def select_vertex(setG, g):\n",
    "    listG = list(setG)\n",
    "    values = [g.degree(i) for i in setG]\n",
    "    return listG[np.argmax(np.array(values))]\n",
    "\n",
    "def mcs(g,h):\n",
    "    stime = time.time()\n",
    "    labelset_g = defaultdict(set)\n",
    "    labelset_h = defaultdict(set)\n",
    "    for node in g.nodes:\n",
    "        labelset_g[g.nodes[node]['label']].add(node)\n",
    "    for node in h.nodes:\n",
    "        labelset_h[h.nodes[node]['label']].add(node)\n",
    "\n",
    "    future = {}\n",
    "    for label in set(labelset_g.keys()).intersection(labelset_h.keys()):\n",
    "        future[str(label)+'-'] = [labelset_g[label], labelset_h[label]]\n",
    "    M, incumbent = {}, {}\n",
    "\n",
    "    def search(future):\n",
    "        if time.time() - stime > 100:\n",
    "            return False\n",
    "        nonlocal incumbent, M, g,h\n",
    "        if len(M) > len(incumbent):\n",
    "            incumbent = M.copy()\n",
    "        bound = len(M) + sum([ min(len(value[0]), len(value[1])) for value in future.values()])\n",
    "        if bound <= len(incumbent):\n",
    "            return \n",
    "        if len(future)==0:\n",
    "            return\n",
    "        selected_label, (setG, setH) = select_label_class(future)\n",
    "        v = select_vertex(setG, g)\n",
    "        for w in setH:\n",
    "            future_ = {}\n",
    "            for cur_label, (setG_, setH_) in future.items():\n",
    "                setG__ = (setG_.intersection([node for node in g.neighbors(v)])).difference([v])\n",
    "                setH__ = (setH_.intersection([node for node in h.neighbors(w)])).difference([w])\n",
    "                if len(setG__) != 0 and len(setH__) != 0:\n",
    "                    future_[cur_label+'1'] = [setG__, setH__]\n",
    "\n",
    "                setG__ = (setG_.intersection([node for node in g.nodes if node not in g.neighbors(v)] )).difference([v])\n",
    "                setH__ = (setH_.intersection([node for node in h.nodes if node not in h.neighbors(w)] )).difference([w])\n",
    "                if len(setG__) != 0 and len(setH__) != 0:\n",
    "                    future_[cur_label+'0'] = [setG__, setH__]\n",
    "            M[v]=w\n",
    "            search(future_)\n",
    "            del M[v]\n",
    "        setG_ = setG.difference([v])\n",
    "        del future[selected_label]\n",
    "        if len(setG_) > 0:\n",
    "            future[selected_label] = [setG_, setH]\n",
    "        search(future)\n",
    "        return True\n",
    "    \n",
    "    if search(future):\n",
    "        return incumbent\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set max degree to 5\n",
      "-----------------------------------------------\n",
      "Loading data:\n",
      "Loading graph data from ./dataspace/graph/yeast/yeast-G.json\n",
      "Removed 0 nodes that lacked proper annotations due to networkx versioning issues\n",
      "File loaded successfully\n",
      "Loading feature from ./dataspace/graph/yeast/yeast-G.json\n",
      "File loaded successfully\n",
      "Loading classmap data from ./dataspace/graph/yeast/yeast-class_map.json\n",
      "File loaded successfully\n",
      "Loaded data.. now preprocessing..\n",
      "Use original edges\n",
      "Generate train edges\n",
      "Number of training edges: 12519\n",
      "Preprocessing finished, graph info:\n",
      "Name: yeast\n",
      "Type: Graph\n",
      "Number of nodes: 3101\n",
      "Number of edges: 12519\n",
      "Average degree:   8.0742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2250it [00:06, 342.00it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-659942185be5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mgraph_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcore_node\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_machine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mori_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mbiggraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery_machine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_subgraph_from_core\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGRAPH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbiggraph\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mGRAPH_SIZE\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_connected\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbiggraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/EPFL/query_embedding/final_code/generate_data/utils/query_machine.py\u001b[0m in \u001b[0;36mcreate_subgraph_from_core\u001b[0;34m(self, core_node, num_nodes)\u001b[0m\n\u001b[1;32m    111\u001b[0m                     \u001b[0mbfs_order\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bfs_order'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbfs_order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dfs_order'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdfs_preorder_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_centroid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/EPFL/query_embedding/final_code/generate_data/utils/query_machine.py\u001b[0m in \u001b[0;36mget_centroid\u001b[0;34m(self, sub_graph)\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0mmax_degree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msub_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0msub_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdegree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmax_degree\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m                 \u001b[0mmax_degree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msub_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdegree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m                 \u001b[0mcentroid_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/networkx/classes/reportviews.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, nbunch, weight)\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnbunch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_weight\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnbunch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnbunch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/networkx/classes/reportviews.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[0mnbrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_succ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbrs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnbrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdd\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnbrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnbrs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnbrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/networkx/classes/coreviews.py\u001b[0m in \u001b[0;36m__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/networkx/classes/coreviews.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/networkx/classes/coreviews.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnode_ok_shorter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNODE_OK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_atlas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_atlas\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNODE_OK\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# for dataset in ['yeast', 'human', 'cora', 'citeseer', 'pubmed', 'wordnet']:\n",
    "#     dim=4\n",
    "#     ori_graph_data = load_data('./dataspace/graph/{}/{}'.format(dataset, dataset), supervised=False, max_degree=5, multiclass=False, use_random_walks=False)\n",
    "\n",
    "#     ori_emb_model = SupervisedGraphSage(ori_graph_data.raw_feats.shape[1], dim, ori_graph_data.num_class)\n",
    "#     ori_emb_model = ori_emb_model.cuda()\n",
    "#     ori_emb_model.load_state_dict(torch.load('model_dim/{}_sup_20_dim{}.pt'.format(dataset, dim)))\n",
    "#     ori_emb_model.set_params(ori_graph_data.full_adj, ori_graph_data.deg, ori_graph_data.feats)\n",
    "#     ori_emb_model.eval()\n",
    "\n",
    "#     ori_graph_emb = F.normalize(ori_emb_model.aggregator(list(range(ori_graph_data.raw_feats.shape[0]))), dim = 1)\n",
    "#     ori_graph_emb = ori_graph_emb.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "#     for i, node in enumerate(ori_graph_data.G.nodes):\n",
    "#         ori_graph_data.G.nodes[node]['label'] = ori_graph_data.multi2single_label[tuple(ori_graph_data.G.nodes[node]['label'])]\n",
    "\n",
    "#     query_machine = GraphQuery(ori_emb_model, \n",
    "#             ori_graph_emb,\n",
    "#             ori_graph_data.G,\n",
    "#             ori_graph_data.id_map,\n",
    "#             ori_graph_data.feats,\n",
    "#             ori_graph_data.raw_feats,\n",
    "#             ori_graph_data.full_adj,\n",
    "#             ori_graph_data.deg)\n",
    "\n",
    "#     def get_embedding_subgraph(subgraph):\n",
    "#         sub_id_map, sub_raw_feats, all_sub_adj, sub_degree = query_machine.create_subgraph_map(subgraph)\n",
    "#         embedding_subgraph = query_machine.embedding_subgraph(sub_raw_feats, all_sub_adj, sub_degree)\n",
    "#         embedding_subgraph = embedding_subgraph.detach().cpu().numpy()\n",
    "\n",
    "#         return embedding_subgraph, sub_id_map\n",
    "\n",
    "\n",
    "#     mcs2emb = defaultdict(list)\n",
    "#     GRAPH_SIZE = 15\n",
    "#     graphs = []\n",
    "#     graph_embeddings = []\n",
    "#     for i, core_node in tqdm(enumerate(query_machine.ori_graph.nodes)):\n",
    "#         biggraph = query_machine.create_subgraph_from_core(core_node, GRAPH_SIZE)\n",
    "#         if len(biggraph) != GRAPH_SIZE or not nx.is_connected(biggraph):\n",
    "#             continue\n",
    "#         sub_id_map, sub_raw_feats, all_sub_adj, sub_degree = query_machine.create_subgraph_map(biggraph)\n",
    "\n",
    "#         embedding_biggraph = query_machine.embedding_subgraph(sub_raw_feats, all_sub_adj, sub_degree)\n",
    "#         embedding_biggraph = embedding_biggraph.detach().cpu().numpy().mean(0)\n",
    "#         if not np.isnan(embedding_biggraph).any():\n",
    "#             graphs.append(biggraph)\n",
    "#             graph_embeddings.append(embedding_biggraph)\n",
    "#     n=len(graphs)\n",
    "#     edit_distances = []\n",
    "#     emb_distances = []\n",
    "#     edit_distances_tuple = []\n",
    "#     for _ in tqdm(range(5000)):\n",
    "#         i, j = random.randint(0, n-1),random.randint(0, n-1)\n",
    "#         graph1 = graphs[i]\n",
    "#         graph2 = graphs[j]\n",
    "#         edit_distance = len(mcs(graph1, graph2))\n",
    "#         edit_distances.append(edit_distance)\n",
    "#         edit_distances_tuple.append( ( (i,j) , edit_distance) )\n",
    "#         emb_distances.append( ((graph_embeddings[i] - graph_embeddings[j])**2).sum() )\n",
    "#     print(Counter(edit_distances))\n",
    "#     print(dataset, dim, spearmanr(edit_distances, emb_distances), pearsonr(edit_distances,emb_distances))\n",
    "#     for dim in [8, 16, 32, 64, 128]:\n",
    "#         ori_graph_data = load_data('./dataspace/graph/{}/{}'.format(dataset, dataset), supervised=False, max_degree=5, multiclass=False, use_random_walks=False)\n",
    "\n",
    "#         ori_emb_model = SupervisedGraphSage(ori_graph_data.raw_feats.shape[1], dim, ori_graph_data.num_class)\n",
    "#         ori_emb_model = ori_emb_model.cuda()\n",
    "#         ori_emb_model.load_state_dict(torch.load('model_dim/{}_sup_20_dim{}.pt'.format(dataset, dim)))\n",
    "#         ori_emb_model.set_params(ori_graph_data.full_adj, ori_graph_data.deg, ori_graph_data.feats)\n",
    "#         ori_emb_model.eval()\n",
    "\n",
    "#         ori_graph_emb = F.normalize(ori_emb_model.aggregator(list(range(ori_graph_data.raw_feats.shape[0]))), dim = 1)\n",
    "#         ori_graph_emb = ori_graph_emb.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "#         for i, node in enumerate(ori_graph_data.G.nodes):\n",
    "#             ori_graph_data.G.nodes[node]['label'] = ori_graph_data.multi2single_label[tuple(ori_graph_data.G.nodes[node]['label'])]\n",
    "\n",
    "#         query_machine = GraphQuery(ori_emb_model, \n",
    "#                 ori_graph_emb,\n",
    "#                 ori_graph_data.G,\n",
    "#                 ori_graph_data.id_map,\n",
    "#                 ori_graph_data.feats,\n",
    "#                 ori_graph_data.raw_feats,\n",
    "#                 ori_graph_data.full_adj,\n",
    "#                 ori_graph_data.deg)\n",
    "\n",
    "#         def get_embedding_subgraph(subgraph):\n",
    "#             sub_id_map, sub_raw_feats, all_sub_adj, sub_degree = query_machine.create_subgraph_map(subgraph)\n",
    "#             embedding_subgraph = query_machine.embedding_subgraph(sub_raw_feats, all_sub_adj, sub_degree)\n",
    "#             embedding_subgraph = embedding_subgraph.detach().cpu().numpy()\n",
    "\n",
    "#             return embedding_subgraph, sub_id_map\n",
    "\n",
    "#         graph_embeddings = []\n",
    "#         for biggraph in tqdm(graphs):\n",
    "#             sub_id_map, sub_raw_feats, all_sub_adj, sub_degree = query_machine.create_subgraph_map(biggraph)\n",
    "\n",
    "#             embedding_biggraph = query_machine.embedding_subgraph(sub_raw_feats, all_sub_adj, sub_degree)\n",
    "#             embedding_biggraph = embedding_biggraph.detach().cpu().numpy().mean(0)\n",
    "#             graph_embeddings.append(embedding_biggraph)\n",
    "                \n",
    "#         n=len(graphs)\n",
    "#         edit_distances = []\n",
    "#         emb_distances = []\n",
    "#         for (i, j), edit_distance in tqdm(edit_distances_tuple):\n",
    "#             edit_distances.append(edit_distance)\n",
    "#             emb_distances.append( ((graph_embeddings[i] - graph_embeddings[j])**2).sum() )\n",
    "#         print(dataset, dim, spearmanr(edit_distances, emb_distances), pearsonr(edit_distances,emb_distances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set max degree to 5\n",
      "-----------------------------------------------\n",
      "Loading data:\n",
      "Loading graph data from ./dataspace/graph/wordnet/wordnet-G.json\n",
      "Removed 0 nodes that lacked proper annotations due to networkx versioning issues\n",
      "File loaded successfully\n",
      "Loading feature from ./dataspace/graph/wordnet/wordnet-G.json\n",
      "File loaded successfully\n",
      "Loading classmap data from ./dataspace/graph/wordnet/wordnet-class_map.json\n",
      "File loaded successfully\n",
      "Loaded data.. now preprocessing..\n",
      "Use original edges\n",
      "Generate train edges\n",
      "Number of training edges: 127124\n",
      "Preprocessing finished, graph info:\n",
      "Name: wordnet\n",
      "Type: Graph\n",
      "Number of nodes: 82670\n",
      "Number of edges: 127124\n",
      "Average degree:   3.0755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "82670it [03:08, 438.58it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-70db3a625c40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mgraph1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraphs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mgraph2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraphs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mmcs_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmcs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmcs_graph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0medit_distance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmcs_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-f44d093f7c4f>\u001b[0m in \u001b[0;36mmcs\u001b[0;34m(g, h)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mincumbent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-f44d093f7c4f>\u001b[0m in \u001b[0;36msearch\u001b[0;34m(future)\u001b[0m\n\u001b[1;32m     50\u001b[0m                     \u001b[0mfuture_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcur_label\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'0'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msetG__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msetH__\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mM\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfuture_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0msetG_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msetG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdifference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-f44d093f7c4f>\u001b[0m in \u001b[0;36msearch\u001b[0;34m(future)\u001b[0m\n\u001b[1;32m     50\u001b[0m                     \u001b[0mfuture_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcur_label\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'0'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msetG__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msetH__\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mM\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfuture_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0msetG_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msetG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdifference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-f44d093f7c4f>\u001b[0m in \u001b[0;36msearch\u001b[0;34m(future)\u001b[0m\n\u001b[1;32m     50\u001b[0m                     \u001b[0mfuture_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcur_label\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'0'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msetG__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msetH__\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mM\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfuture_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0msetG_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msetG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdifference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-f44d093f7c4f>\u001b[0m in \u001b[0;36msearch\u001b[0;34m(future)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msetG_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0mfuture\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mselected_label\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msetG_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msetH\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-f44d093f7c4f>\u001b[0m in \u001b[0;36msearch\u001b[0;34m(future)\u001b[0m\n\u001b[1;32m     45\u001b[0m                     \u001b[0mfuture_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcur_label\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msetG__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msetH__\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                 \u001b[0msetG__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msetG_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdifference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m                 \u001b[0msetH__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msetH_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdifference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msetG__\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msetH__\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-f44d093f7c4f>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     45\u001b[0m                     \u001b[0mfuture_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcur_label\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msetG__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msetH__\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                 \u001b[0msetG__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msetG_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdifference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m                 \u001b[0msetH__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msetH_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdifference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msetG__\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msetH__\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/networkx/classes/coreviews.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnode_ok_shorter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNODE_OK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_atlas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_atlas\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNODE_OK\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/networkx/classes/coreviews.py\u001b[0m in \u001b[0;36mnew_node_ok\u001b[0;34m(nbr)\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_atlas\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNODE_OK\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mnew_node_ok\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNODE_OK\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEDGE_OK\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mFilterAtlas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_atlas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_node_ok\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Key {} not found\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/networkx/classes/filters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for dataset in ['wordnet']:\n",
    "    dim=4\n",
    "    ori_graph_data = load_data('./dataspace/graph/{}/{}'.format(dataset, dataset), supervised=False, max_degree=5, multiclass=False, use_random_walks=False)\n",
    "\n",
    "    ori_emb_model = SupervisedGraphSage(ori_graph_data.raw_feats.shape[1], dim, ori_graph_data.num_class)\n",
    "    ori_emb_model = ori_emb_model.cuda()\n",
    "    ori_emb_model.load_state_dict(torch.load('model_dim/{}_sup_20_dim{}.pt'.format(dataset, dim)))\n",
    "    ori_emb_model.set_params(ori_graph_data.full_adj, ori_graph_data.deg, ori_graph_data.feats)\n",
    "    ori_emb_model.eval()\n",
    "\n",
    "    ori_graph_emb = F.normalize(ori_emb_model.aggregator(list(range(ori_graph_data.raw_feats.shape[0]))), dim = 1)\n",
    "    ori_graph_emb = ori_graph_emb.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "    for i, node in enumerate(ori_graph_data.G.nodes):\n",
    "        ori_graph_data.G.nodes[node]['label'] = ori_graph_data.multi2single_label[tuple(ori_graph_data.G.nodes[node]['label'])]\n",
    "\n",
    "    query_machine = GraphQuery(ori_emb_model, \n",
    "            ori_graph_emb,\n",
    "            ori_graph_data.G,\n",
    "            ori_graph_data.id_map,\n",
    "            ori_graph_data.feats,\n",
    "            ori_graph_data.raw_feats,\n",
    "            ori_graph_data.full_adj,\n",
    "            ori_graph_data.deg)\n",
    "\n",
    "    def get_embedding_subgraph(subgraph):\n",
    "        sub_id_map, sub_raw_feats, all_sub_adj, sub_degree = query_machine.create_subgraph_map(subgraph)\n",
    "        embedding_subgraph = query_machine.embedding_subgraph(sub_raw_feats, all_sub_adj, sub_degree)\n",
    "        embedding_subgraph = embedding_subgraph.detach().cpu().numpy()\n",
    "\n",
    "        return embedding_subgraph, sub_id_map\n",
    "\n",
    "\n",
    "    mcs2emb = defaultdict(list)\n",
    "    GRAPH_SIZE = 15\n",
    "    graphs = []\n",
    "    graph_embeddings = []\n",
    "    for i, core_node in tqdm(enumerate(query_machine.ori_graph.nodes)):\n",
    "        biggraph = query_machine.create_subgraph_from_core(core_node, GRAPH_SIZE)\n",
    "        if len(biggraph) != GRAPH_SIZE or not nx.is_connected(biggraph):\n",
    "            continue\n",
    "        sub_id_map, sub_raw_feats, all_sub_adj, sub_degree = query_machine.create_subgraph_map(biggraph)\n",
    "\n",
    "        embedding_biggraph = query_machine.embedding_subgraph(sub_raw_feats, all_sub_adj, sub_degree)\n",
    "        embedding_biggraph = embedding_biggraph.detach().cpu().numpy().mean(0)\n",
    "        if not np.isnan(embedding_biggraph).any():\n",
    "            graphs.append(biggraph)\n",
    "            graph_embeddings.append(embedding_biggraph)\n",
    "    n=len(graphs)\n",
    "    edit_distances = []\n",
    "    emb_distances = []\n",
    "    edit_distances_tuple = []\n",
    "    while len(emb_distances)<5000:\n",
    "        i, j = random.randint(0, n-1),random.randint(0, n-1)\n",
    "        graph1 = graphs[i]\n",
    "        graph2 = graphs[j]\n",
    "        mcs_graph = mcs(graph1, graph2)\n",
    "        if mcs_graph:\n",
    "            edit_distance = len(mcs_graph)\n",
    "            edit_distances.append(edit_distance)\n",
    "            edit_distances_tuple.append( ( (i,j) , edit_distance) )\n",
    "            emb_distances.append( ((graph_embeddings[i] - graph_embeddings[j])**2).sum() )\n",
    "            print(len(emb_distances),end='\\r')\n",
    "    print(Counter(edit_distances))\n",
    "    print(dataset, dim, spearmanr(edit_distances, emb_distances), pearsonr(edit_distances,emb_distances))\n",
    "    for dim in [8, 16, 32, 64, 128]:\n",
    "        ori_graph_data = load_data('./dataspace/graph/{}/{}'.format(dataset, dataset), supervised=False, max_degree=5, multiclass=False, use_random_walks=False)\n",
    "\n",
    "        ori_emb_model = SupervisedGraphSage(ori_graph_data.raw_feats.shape[1], dim, ori_graph_data.num_class)\n",
    "        ori_emb_model = ori_emb_model.cuda()\n",
    "        ori_emb_model.load_state_dict(torch.load('model_dim/{}_sup_20_dim{}.pt'.format(dataset, dim)))\n",
    "        ori_emb_model.set_params(ori_graph_data.full_adj, ori_graph_data.deg, ori_graph_data.feats)\n",
    "        ori_emb_model.eval()\n",
    "\n",
    "        ori_graph_emb = F.normalize(ori_emb_model.aggregator(list(range(ori_graph_data.raw_feats.shape[0]))), dim = 1)\n",
    "        ori_graph_emb = ori_graph_emb.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "        for i, node in enumerate(ori_graph_data.G.nodes):\n",
    "            ori_graph_data.G.nodes[node]['label'] = ori_graph_data.multi2single_label[tuple(ori_graph_data.G.nodes[node]['label'])]\n",
    "\n",
    "        query_machine = GraphQuery(ori_emb_model, \n",
    "                ori_graph_emb,\n",
    "                ori_graph_data.G,\n",
    "                ori_graph_data.id_map,\n",
    "                ori_graph_data.feats,\n",
    "                ori_graph_data.raw_feats,\n",
    "                ori_graph_data.full_adj,\n",
    "                ori_graph_data.deg)\n",
    "\n",
    "        def get_embedding_subgraph(subgraph):\n",
    "            sub_id_map, sub_raw_feats, all_sub_adj, sub_degree = query_machine.create_subgraph_map(subgraph)\n",
    "            embedding_subgraph = query_machine.embedding_subgraph(sub_raw_feats, all_sub_adj, sub_degree)\n",
    "            embedding_subgraph = embedding_subgraph.detach().cpu().numpy()\n",
    "\n",
    "            return embedding_subgraph, sub_id_map\n",
    "\n",
    "        graph_embeddings = []\n",
    "        for biggraph in tqdm(graphs):\n",
    "            sub_id_map, sub_raw_feats, all_sub_adj, sub_degree = query_machine.create_subgraph_map(biggraph)\n",
    "\n",
    "            embedding_biggraph = query_machine.embedding_subgraph(sub_raw_feats, all_sub_adj, sub_degree)\n",
    "            embedding_biggraph = embedding_biggraph.detach().cpu().numpy().mean(0)\n",
    "            graph_embeddings.append(embedding_biggraph)\n",
    "                \n",
    "        n=len(graphs)\n",
    "        edit_distances = []\n",
    "        emb_distances = []\n",
    "        for (i, j), edit_distance in tqdm(edit_distances_tuple):\n",
    "            edit_distances.append(edit_distance)\n",
    "            emb_distances.append( ((graph_embeddings[i] - graph_embeddings[j])**2).sum() )\n",
    "        print(dataset, dim, spearmanr(edit_distances, emb_distances), pearsonr(edit_distances,emb_distances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({12: 1547, 11: 1108, 10: 504, 9: 383, 13: 320, 8: 227, 7: 177, 6: 160, 5: 136, 4: 133, 3: 108, 2: 99, 1: 88, 14: 10})\n",
      "wordnet 4 SpearmanrResult(correlation=-0.8612662991422443, pvalue=0.0) (-0.8996118552146768, 0.0)\n",
      "Set max degree to 5\n",
      "-----------------------------------------------\n",
      "Loading data:\n",
      "Loading graph data from ./dataspace/graph/wordnet/wordnet-G.json\n",
      "Removed 0 nodes that lacked proper annotations due to networkx versioning issues\n",
      "File loaded successfully\n",
      "Loading feature from ./dataspace/graph/wordnet/wordnet-G.json\n",
      "File loaded successfully\n",
      "Loading classmap data from ./dataspace/graph/wordnet/wordnet-class_map.json\n",
      "File loaded successfully\n",
      "Loaded data.. now preprocessing..\n",
      "Use original edges\n",
      "Generate train edges\n",
      "Number of training edges: 127124\n",
      "Preprocessing finished, graph info:\n",
      "Name: wordnet\n",
      "Type: Graph\n",
      "Number of nodes: 82670\n",
      "Number of edges: 127124\n",
      "Average degree:   3.0755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 74062/74062 [01:59<00:00, 622.13it/s]\n",
      "100%|| 5000/5000 [00:00<00:00, 227459.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wordnet 8 SpearmanrResult(correlation=-0.8630103241999257, pvalue=0.0) (-0.9457853482254593, 0.0)\n",
      "Set max degree to 5\n",
      "-----------------------------------------------\n",
      "Loading data:\n",
      "Loading graph data from ./dataspace/graph/wordnet/wordnet-G.json\n",
      "Removed 0 nodes that lacked proper annotations due to networkx versioning issues\n",
      "File loaded successfully\n",
      "Loading feature from ./dataspace/graph/wordnet/wordnet-G.json\n",
      "File loaded successfully\n",
      "Loading classmap data from ./dataspace/graph/wordnet/wordnet-class_map.json\n",
      "File loaded successfully\n",
      "Loaded data.. now preprocessing..\n",
      "Use original edges\n",
      "Generate train edges\n",
      "Number of training edges: 127124\n",
      "Preprocessing finished, graph info:\n",
      "Name: wordnet\n",
      "Type: Graph\n",
      "Number of nodes: 82670\n",
      "Number of edges: 127124\n",
      "Average degree:   3.0755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 74062/74062 [01:59<00:00, 620.75it/s]\n",
      "100%|| 5000/5000 [00:00<00:00, 227326.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wordnet 16 SpearmanrResult(correlation=-0.8634712339192067, pvalue=0.0) (-0.9453260580121946, 0.0)\n",
      "Set max degree to 5\n",
      "-----------------------------------------------\n",
      "Loading data:\n",
      "Loading graph data from ./dataspace/graph/wordnet/wordnet-G.json\n",
      "Removed 0 nodes that lacked proper annotations due to networkx versioning issues\n",
      "File loaded successfully\n",
      "Loading feature from ./dataspace/graph/wordnet/wordnet-G.json\n",
      "File loaded successfully\n",
      "Loading classmap data from ./dataspace/graph/wordnet/wordnet-class_map.json\n",
      "File loaded successfully\n",
      "Loaded data.. now preprocessing..\n",
      "Use original edges\n",
      "Generate train edges\n",
      "Number of training edges: 127124\n",
      "Preprocessing finished, graph info:\n",
      "Name: wordnet\n",
      "Type: Graph\n",
      "Number of nodes: 82670\n",
      "Number of edges: 127124\n",
      "Average degree:   3.0755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 74062/74062 [01:59<00:00, 620.80it/s]\n",
      "100%|| 5000/5000 [00:00<00:00, 223901.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wordnet 32 SpearmanrResult(correlation=-0.8622446078404036, pvalue=0.0) (-0.9412014976257482, 0.0)\n",
      "Set max degree to 5\n",
      "-----------------------------------------------\n",
      "Loading data:\n",
      "Loading graph data from ./dataspace/graph/wordnet/wordnet-G.json\n",
      "Removed 0 nodes that lacked proper annotations due to networkx versioning issues\n",
      "File loaded successfully\n",
      "Loading feature from ./dataspace/graph/wordnet/wordnet-G.json\n",
      "File loaded successfully\n",
      "Loading classmap data from ./dataspace/graph/wordnet/wordnet-class_map.json\n",
      "File loaded successfully\n",
      "Loaded data.. now preprocessing..\n",
      "Use original edges\n",
      "Generate train edges\n",
      "Number of training edges: 127124\n",
      "Preprocessing finished, graph info:\n",
      "Name: wordnet\n",
      "Type: Graph\n",
      "Number of nodes: 82670\n",
      "Number of edges: 127124\n",
      "Average degree:   3.0755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 74062/74062 [01:59<00:00, 619.57it/s]\n",
      "100%|| 5000/5000 [00:00<00:00, 210272.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wordnet 64 SpearmanrResult(correlation=-0.8615557754842785, pvalue=0.0) (-0.9417961211792564, 0.0)\n",
      "Set max degree to 5\n",
      "-----------------------------------------------\n",
      "Loading data:\n",
      "Loading graph data from ./dataspace/graph/wordnet/wordnet-G.json\n",
      "Removed 0 nodes that lacked proper annotations due to networkx versioning issues\n",
      "File loaded successfully\n",
      "Loading feature from ./dataspace/graph/wordnet/wordnet-G.json\n",
      "File loaded successfully\n",
      "Loading classmap data from ./dataspace/graph/wordnet/wordnet-class_map.json\n",
      "File loaded successfully\n",
      "Loaded data.. now preprocessing..\n",
      "Use original edges\n",
      "Generate train edges\n",
      "Number of training edges: 127124\n",
      "Preprocessing finished, graph info:\n",
      "Name: wordnet\n",
      "Type: Graph\n",
      "Number of nodes: 82670\n",
      "Number of edges: 127124\n",
      "Average degree:   3.0755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 74062/74062 [01:58<00:00, 625.57it/s]\n",
      "100%|| 5000/5000 [00:00<00:00, 205116.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wordnet 128 SpearmanrResult(correlation=-0.8619479520066587, pvalue=0.0) (-0.9385003850698971, 0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n=len(graphs)\n",
    "edit_distances = []\n",
    "emb_distances = []\n",
    "edit_distances_tuple = []\n",
    "while len(emb_distances)<5000:\n",
    "    i, j = random.randint(0, n-1),random.randint(0, n-1)\n",
    "    graph1 = graphs[i]\n",
    "    graph2 = graphs[j]\n",
    "    mcs_graph = mcs(graph1, graph2)\n",
    "    if mcs_graph:\n",
    "        edit_distance = len(mcs_graph)\n",
    "        edit_distances.append(edit_distance)\n",
    "        edit_distances_tuple.append( ( (i,j) , edit_distance) )\n",
    "        emb_distances.append( ((graph_embeddings[i] - graph_embeddings[j])**2).sum() )\n",
    "        print(len(emb_distances),end='\\r')\n",
    "print(Counter(edit_distances))\n",
    "print(dataset, dim, spearmanr(edit_distances, emb_distances), pearsonr(edit_distances,emb_distances))\n",
    "for dim in [8, 16, 32, 64, 128]:\n",
    "    ori_graph_data = load_data('./dataspace/graph/{}/{}'.format(dataset, dataset), supervised=False, max_degree=5, multiclass=False, use_random_walks=False)\n",
    "\n",
    "    ori_emb_model = SupervisedGraphSage(ori_graph_data.raw_feats.shape[1], dim, ori_graph_data.num_class)\n",
    "    ori_emb_model = ori_emb_model.cuda()\n",
    "    ori_emb_model.load_state_dict(torch.load('model_dim/{}_sup_20_dim{}.pt'.format(dataset, dim)))\n",
    "    ori_emb_model.set_params(ori_graph_data.full_adj, ori_graph_data.deg, ori_graph_data.feats)\n",
    "    ori_emb_model.eval()\n",
    "\n",
    "    ori_graph_emb = F.normalize(ori_emb_model.aggregator(list(range(ori_graph_data.raw_feats.shape[0]))), dim = 1)\n",
    "    ori_graph_emb = ori_graph_emb.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "    for i, node in enumerate(ori_graph_data.G.nodes):\n",
    "        ori_graph_data.G.nodes[node]['label'] = ori_graph_data.multi2single_label[tuple(ori_graph_data.G.nodes[node]['label'])]\n",
    "\n",
    "    query_machine = GraphQuery(ori_emb_model, \n",
    "            ori_graph_emb,\n",
    "            ori_graph_data.G,\n",
    "            ori_graph_data.id_map,\n",
    "            ori_graph_data.feats,\n",
    "            ori_graph_data.raw_feats,\n",
    "            ori_graph_data.full_adj,\n",
    "            ori_graph_data.deg)\n",
    "\n",
    "    def get_embedding_subgraph(subgraph):\n",
    "        sub_id_map, sub_raw_feats, all_sub_adj, sub_degree = query_machine.create_subgraph_map(subgraph)\n",
    "        embedding_subgraph = query_machine.embedding_subgraph(sub_raw_feats, all_sub_adj, sub_degree)\n",
    "        embedding_subgraph = embedding_subgraph.detach().cpu().numpy()\n",
    "\n",
    "        return embedding_subgraph, sub_id_map\n",
    "\n",
    "    graph_embeddings = []\n",
    "    for biggraph in tqdm(graphs):\n",
    "        sub_id_map, sub_raw_feats, all_sub_adj, sub_degree = query_machine.create_subgraph_map(biggraph)\n",
    "\n",
    "        embedding_biggraph = query_machine.embedding_subgraph(sub_raw_feats, all_sub_adj, sub_degree)\n",
    "        embedding_biggraph = embedding_biggraph.detach().cpu().numpy().mean(0)\n",
    "        graph_embeddings.append(embedding_biggraph)\n",
    "\n",
    "    n=len(graphs)\n",
    "    edit_distances = []\n",
    "    emb_distances = []\n",
    "    for (i, j), edit_distance in tqdm(edit_distances_tuple):\n",
    "        edit_distances.append(edit_distance)\n",
    "        emb_distances.append( ((graph_embeddings[i] - graph_embeddings[j])**2).sum() )\n",
    "    print(dataset, dim, spearmanr(edit_distances, emb_distances), pearsonr(edit_distances,emb_distances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
